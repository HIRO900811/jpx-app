import requests
from bs4 import BeautifulSoup
import pandas as pd
from io import BytesIO
from openpyxl import load_workbook

# JPXã®å»ºç‰ãƒšãƒ¼ã‚¸URL
JPX_URL = "https://www.jpx.co.jp/markets/derivatives/trading-volume/index.html"

# æœ€æ–°Excelãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’å–å¾—
def get_latest_excel_url():
    res = requests.get(JPX_URL)
    soup = BeautifulSoup(res.text, 'html.parser')
    for a in soup.find_all('a', href=True):
        href = a['href']
        if href.endswith(".xlsx") and "interest" in href.lower():
            return "https://www.jpx.co.jp" + href if href.startswith("/") else href
    return None

# Excelã®ä¸­èº«ã‚’HTMLã«å¤‰æ›ã—ã¦è¿”ã™
def parse_excel_to_html():
    url = get_latest_excel_url()
    if not url:
        return "<p>âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚</p>"

    res = requests.get(url)
    excel_file = BytesIO(res.content)
    df_dict = pd.read_excel(excel_file, sheet_name=None)

    html = ""
    for sheet_name, df in df_dict.items():
        df.fillna(method='ffill', inplace=True)
        html += f"<h2>{sheet_name}</h2>\n"
        html += df.to_html(classes="table table-bordered", index=False)
    return html

# Excelã‹ã‚‰ç‰¹å®šã®ã‚»ãƒ«ã‚’æŠ½å‡º
def extract_specific_cells_from_excel(xlsx_bytes):
    workbook = load_workbook(BytesIO(xlsx_bytes), data_only=True)

    # ğŸ” ã‚·ãƒ¼ãƒˆåä¸€è¦§ã‚’è¡¨ç¤º
    print("ğŸ“„ ã‚·ãƒ¼ãƒˆä¸€è¦§:", workbook.sheetnames)

    sheet_name = "ãƒ‡ãƒªãƒãƒ†ã‚£ãƒ–å»ºç‰æ®‹é«˜çŠ¶æ³"
    if sheet_name not in workbook.sheetnames:
        return f"âŒ ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

    ws = workbook[sheet_name]

    # ã‚»ãƒ«ã‚’è¾æ›¸ã«ã¾ã¨ã‚ã¦è¿”ã™
    cells = {
        "nikkei225": ws["B30"].value,
        "nikkei225_diff": ws["E30"].value,
        "nikkei225_total_diff": ws["E49"].value,
        "nikkei225mini_total": ws["L52"].value,
        "topix": ws["B50"].value,
        "topix_diff": ws["E50"].value,
        "put_volume": ws["C295"].value,
        "put_diff": ws["E295"].value,
        "call_volume": ws["C296"].value,
        "call_diff": ws["E296"].value,
    }

    return cells

#JPXã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿APIã‹ã‚‰ã€Œæ—¥çµŒ225ã€ã®å…ˆç‰©ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹
def fetch_nikkei225_from_api():
    url = "https://port.jpx.co.jp/jpxhp/jcgi/wrap/qjsonp.aspx?F=ctl/future&DISPTYPE=daytime"
    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    try:
        res = requests.get(url, headers=headers, timeout=5)
        res.encoding = res.apparent_encoding
        data = res.json()

        if data["section1"]["status"] == 0 and data["section1"]["hitcount"] > 0:
            rows = data["section1"]["data"]

            for item in rows:
                if "æ—¥çµŒ225" in item.get("name", ""):
                    for future in item["future"]:
                        return {
                            "name": item["name"],
                            "limit_month": future["DELI"],
                            "price": future["DPP"],
                            "diff": future["DYWP"]
                        }
        return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

    except Exception as e:
        return {"error": f"APIã‚¨ãƒ©ãƒ¼: {str(e)}"}

#å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
def analyze_market_trend(nikkei_data, extracted_data):
    result = {
        "futures_trend": "",
        "options_trend": "",
    }

    # --- å…±é€š: æ ªä¾¡å‰æ—¥æ¯”ï¼ˆ+/-ï¼‰
    price_change = nikkei_data.get("diff", "")
    is_price_up = price_change.startswith("+")
    is_price_down = price_change.startswith("-")

    # --- å…ˆç‰©å»ºç‰å‹•å‘ ---
    try:
        nikkei225_diff = int(extracted_data.get("nikkei225_diff", 0))
        nikkei225_total_diff = int(extracted_data.get("nikkei225_total_diff", 0))
        is_futures_increase = nikkei225_diff > 0 and nikkei225_total_diff > 0
        is_futures_decrease = nikkei225_diff < 0 and nikkei225_total_diff < 0

        if is_price_up and is_futures_increase:
            result["futures_trend"] = "ğŸ“ˆ ä¸Šæ˜‡æ–¹å‘ã®ãƒˆãƒ¬ãƒ³ãƒ‰ç™ºç”Ÿã‚’æ„è­˜"
        elif is_price_up and is_futures_decrease:
            result["futures_trend"] = "âš  ä¸Šæ˜‡ã¯é•·ç¶šãã›ãšåè»¢ä¸‹è½ã®å¯èƒ½æ€§"
        elif is_price_down and is_futures_increase:
            result["futures_trend"] = "ğŸ”„ ä¸‹è½ã¯é•·ç¶šãã›ãšå†ä¸Šæ˜‡ã®å¯èƒ½æ€§"
        elif is_price_down and is_futures_decrease:
            result["futures_trend"] = "ğŸ“‰ ä¸‹è½æ–¹å‘ã®ãƒˆãƒ¬ãƒ³ãƒ‰ç™ºç”Ÿã‚’æ„è­˜"
        else:
            result["futures_trend"] = "â” åˆ¤æ–­å›°é›£"

    except Exception as e:
        result["futures_trend"] = f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"

    # --- ã‚ªãƒ—ã‚·ãƒ§ãƒ³å»ºç‰å‹•å‘ ---
    try:
        call_diff = int(extracted_data.get("call_diff", 0))
        put_diff = int(extracted_data.get("put_diff", 0))

        if is_price_up and call_diff > 0:
            result["options_trend"] = "ğŸ’ª å¼·æ°—ï¼ˆä¸Šæ˜‡ï¼†ã‚³ãƒ¼ãƒ«å»ºç‰å¢—ï¼‰"
        elif is_price_up and call_diff < 0:
            result["options_trend"] = "ğŸ“‰ ä¸Šæ˜‡ã¯é•·ãç¶šãã«ãã„ï¼ˆã‚³ãƒ¼ãƒ«æ¸›å°‘ï¼‰"
        elif is_price_down and put_diff > 0:
            result["options_trend"] = "ğŸ˜¨ å¼±æ°—ï¼ˆä¸‹è½ï¼†ãƒ—ãƒƒãƒˆå»ºç‰å¢—ï¼‰"
        elif is_price_down and put_diff < 0:
            result["options_trend"] = "ğŸ“ˆ ä¸‹è½ã¯é•·ç¶šãã›ãšåè»¢ä¸Šæ˜‡ã®å¯èƒ½æ€§"
        else:
            result["options_trend"] = "â” åˆ¤æ–­å›°é›£"

    except Exception as e:
        result["options_trend"] = f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"

    return result